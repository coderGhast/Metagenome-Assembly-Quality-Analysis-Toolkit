\chapter{Evaluation}
This chapter attempts to evaluate my project as a whole, including how well I felt I carried out my analysis of the problem, designed and implemented the application, whether I feel it would be useful to anybody, whether the resulting application met the project objectives and what I could have done differently, or could be improved upon.

\section{Requirements Analysis}
When looking back on the original problem stated, the requirements I set for the application and the resulting application now that the project has finished, I both believe that I made some good choices and bad choices in what I selected to do, and whether it was worthwhile to produce for an actual user.

On the one hand, by selecting to create a web service that allows users to put in FASTA files and inspect the contiguous reads within that file and carry out a number of quality inspections on the data is a great idea. Having a single place to do this with a page that allows the user to view a number of statistics about their data could be highly useful. However, when I think about my choice of working with GC content and Open Reading Frames, and not understanding the domain enough to implement them faster than I did, I feel like perhaps it would have been a better idea to start with k-mer frequency analysis, as this may have been a better measure of quality than what the current application does.

While this may be the case, the way I did develop the application probably helped me understand the domain a little better than if I did begin with k-mer frequency analysis, even if I just consumed output from 3rd party software, and so while the application may lack in some usefulness, what I gained from following the route that I did may have been better in the long run, if I were to continue developing the application and add the functionality of k-mer frequency analysis.

It is for this reason I also feel justified in designing my application as a web service, where adding additional functionality to serve to a user from somewhere it is hosted on allows multiple features to be added without the demand of processing power or memory on a users machine if the application were a regular software application for them to run locally. It does come with the downside that in order to be able to process very large user requests it needs to be hosted on a powerful machine, but as the cost of computing power and memory lowers year by year, it is possible to do this if the demand were there.

\section{Technical Achievement}
The resulting application is a piece of software that carries out a number of tasks, and fulfills each of the functional requirements I set out to do, except for those previously mentioned, has test coverage for the functionality and could have a potentially useful role with those who deal with sequence assembly files. The technical challenge of implementing such an application began with understanding the domain, selecting suitable technologies and then carrying out the development within my development lifecycle plan with XP and Scrum.

The application does give a user access to information about their assembly file that they wouldn't have unless they used multiple different tools elsewhere and combined those results themselves. It is built upon Spring Framework, using the MVC framework design pattern and presented as a web service with a lot of room to grow over time with new techniques for quality assessment. I believe that the technical achievement I made from developing this project is pretty good. I got to use technologies I was unfamiliar with (Spring Framework, Thymeleaf, Plotly.js), develop using an agile methodology to appropriately evolve the application design(XP, Scrum), use known software development techniques and practices (MVC, RESTful web service, etc) and came out with an application that produces results that can be tested against requirements.

I am pleased with my choice of technologies, and know that while it would have been possibly to develop the application in a different language (Ruby, C++, etc) or even develop it as a stand-alone application and not as a web service, I stand by my decisions that they were what I felt were the most suitable choices for this application for my implementation, understanding and knowledges. There are a number of technical improvements that could be done, and these will be discussed in the next section.

\subsection{Future Work}
\subsubsection{Improvements}
Within the current application, there are a number of improvements I would like to carry out. Understandably, there is always room for more refactoring and improvement of the code. As my experience as a software developer grows, so will my skill in refactoring and code design. I cannot claim anything as the best it can possibly be, and so I will always say there is room for improvement in the code and application design.

On the subject of design, the front end design of the user interface also has much room for improvement. This can come in the form of better HTML and CSS layouts, colour choices, better explanations of the applications use, and most importantly, better design of the results. I am pleased with how some of the results are displayed, in particular the display of the list of contiguous reads and the Open Reading Frame results tab are both areas I am pleased with. The GC content chart I feel could be better in demonstrating areas of drastic differences rather than just differences in individual windows over and under a threshold with the mean. This could be done with sliding windows with multiple passes using different window sizes (of reasonable length) and then display better results to a user.

Likewise, the `Superframe' could also be improved. While its function is useful to display to a user where there are matches between protein coding regions and areas of high GC content, outside of the threshold from the mean, I know that if I had more time to work on the application I could find more and better ways of demonstrating this to a user, and better ways on reporting on which GC windows could be `natural' occurrences of high GC content and which cannot be explained (through a lack of an ORF Location or being lower than the threshold of the mean).

There is also room for improvement in the validation of parameters, and giving the user a reason about why their input of parameters or data failed. Right now the application will return a generic error page any time an exception is thrown in the application, or if they input bad data for parameters the application will ignore it and put them back on the page to try again, but won't indicate why this is the case. I attempted many times to get this functionality to work with Thymeleaf and Spring but couldn't get it to function. It is another feature that I feel if I had more time to put into the project I could find the solution.

\subsubsection{Additional Functionality}
Along with the improvements to the existing code and functionality, there are a number of features I would like to implement too. First and foremost, once the improvements had been carried out, I would like to allow a user to upload their own file rather than just pasting in data. This would include decent validation of the users file and implementing restrictions on file size too (this could be altered, based on where the application was hosted and how much memory would be allowed to be alloted to the application).

I would definitely want to implement k-mer frequency analysis, too. Beginning with a prototype, even if it was not very efficient, I would attempt to develop my own algorithm for the application, and also consume the results from the applications that already do k-mer frequency analysis and compare my own results against it, and then decide from there the best way to implement it. I do feel that self-implementing it would be better than 3rd party software, however, as I still stand by that having to rely on 3rd party systems can sometimes lead to issues in the future with maintainability should they be removed, modified or no longer supported, unless there is no other choice but to use them.

The potential to tie the application in with sending requests to NCBI's BLAST for checking if contiguous reads, or parts of them, have reference sequences would also be a great feature to provide to the user as a way of determining if the have a useful and quality contiguous read too. This ties in with thinking of other and better ways of reporting on the quality of the users assembly data. If given more time, and with the domain knowledge now, I could think of other ways that could demonstrate quality to a user, on their own file, on individual contiguous reads, on portions of data, through visual techniques, confidence factors and more. There is so much room to expand the application that it could become a fully fledged software application taken forward over a year or more, if someone wished to do so, to present the ultimate toolkit for reporting on metagenome assembly quality.

If I were to begin the project again from scratch, with my current knowledge of the application and the domain, I feel like I could implement what I have done already a lot faster, finish the improvements, work through k-mer frequency analysis and try to find additional ways of reporting on the quality of the data, perhaps seeking out groups of potential users and really drilling into the project problem and what would be the most useful to them outside of my own ideas.

\section{Project Management}
Now that the project has been completed, I look back on my decision to use and adapt Scrum and Extreme Programming agile approaches for the project lifecycle and think that they were very useful in helping me design, plan, test and work through the tasks that need to be done, but that perhaps it would have been a better choice to use Feature Driven Development (FDD). I cannot say that what would have been produced if I used FDD would have been produced any faster or better than using the Scrum/XP hybrid, but that it could be a possibility to use if I started the project again.

For the most part, I found that using Scrum and XP helped, especially the practices of XP. There are a number of XP practices that I could not implement, however, such as pair programming, which is key to the success of XP in that it ensures that the Test Driven Development and refactoring carried out on the application are reasonable and logical, and not a single developer in a silo believing themselves to be doing the right thing but instead making errors or being inefficient.

With Scrum, while breaking down functionality into User Stories was helpful, sometimes it became trivial to break things down into much smaller slices and create tasks for simple processes, such as `Add button for inspection'. On the other hand, iterative development through Sprints, being able to reflect on the application with Sprint Retrospectives and daily stand-ups with my peers was extremely useful for motivation and discussions of development to help my thought processes.

Using the Pomodoro technique was also useful, as it helped me keep track of how I was doing for work each day, stay focused, find time to work when I might normally put off doing something and made sure I didn't overwork too. It'd definitely a technique that I will put to good use in the future of both software engineering and other creative projects.

\section{Final Conclusion}
Overall, I look back on the project and see an application that met some of the original requirements, where the requirements were slightly hazy and unknown to begin with but produces a potentially useful tool to those who want to look for quality issues in their assembly data. There is large room for improvement and advanced functionality with the tool to be even more useful to users, and if given more time this could be done. The project process was mostly successful, although motivation during the beginning of the project was low due to not fully understanding the domain or requirements of the finished application.

Through developing the application to find a solution to the project topic, I learned a number of things about the domain of metagenomics and technologies that exist to find quality in sequence data, new technologies and frameworks and about myself, what motivates me and what would be good practices to use for future self-driven projects. There are multiple things I would do differently if I were to start again, such as those mentioned in the previous section, but for the most part I feel I have accomplished a body of work that set out to do a task and completed enough of it that a user could feasibly get some use out of the tool, with the code design being good enough to be maintained into the future.

% Examiners expect to find in your dissertation a section addressing such questions as:

%\begin{itemize}
%   \item Were the requirements correctly identified? 
%   \item Were the design decisions correct?
%   \item Could a more suitable set of tools have been chosen?
%   \item How well did the software meet the needs of those who were expecting to use it?
%   \item How well were any other project aims achieved?
%   \item If you were starting again, what would you do differently?
%\end{itemize}

% Such material is regarded as an important part of the dissertation; it should demonstrate that you are capable not only of carrying out a piece of work but also of thinking critically about how you did it and how you might have done it better. This is seen as an important part of an honours degree. 

% There will be good things and room for improvement with any project. As you write this section, identify and discuss the parts of the work that went well and also consider ways in which the work could be improved. 

% Review the discussion on the Evaluation section from the lectures. A recording is available on Blackboard. 
